{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup the data for analysis random forest\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cwd = os.getcwd() # global variable ick\n",
    "# cwd = cwd.replace('/','\\\\')\n",
    "# print(cwd)\n",
    "\n",
    "\n",
    "# clean up column names\n",
    "\n",
    "\n",
    "    \n",
    "def fix_col_name(col_split):\n",
    "        new_string = col_split[1].replace('(','')\n",
    "        new_string = new_string.replace(')','')\n",
    "        new_string = new_string.replace(',','-')\n",
    "        new_string = new_string.replace('BodyBody','Body')\n",
    "        new_string = new_string.replace('Body','')\n",
    "        new_string = new_string.replace('Mag','')\n",
    "        new_string = new_string.replace('mean','Mean')\n",
    "        new_string = new_string.replace('std','STD')\n",
    "        return(new_string)\n",
    "  \n",
    "def trans_columns():\n",
    "\t###  get's column names from feature_file should be same for train and test data.  Can use same col_list\n",
    "\tcol_list =[]\n",
    "\tx = 0\n",
    "\twith open('features.txt','r+') as feature_file:\n",
    "\t    for line in feature_file: # one line is one column\n",
    "\t#         print(line)\n",
    "\t        col_split = line.split() # splits the numbers and characters from the column into seperate fields to work with\n",
    "\t#         print(col_split)\n",
    "\t        new_col = fix_col_name(col_split)\n",
    "\t#         print(new_col)\n",
    "\t        col_list.append(new_col + col_split[0])\n",
    "\t#     col_list = remove_dups(col_list)\n",
    "\t#         break # stop at one record\n",
    "\treturn(col_list)\n",
    "\n",
    "\n",
    "def get_data(col_list):\n",
    "\t# reads file into df.  Modify to pass location for train and test.\n",
    "\n",
    "\ttest_file = os.path.normpath(cwd + '/test/X_test.txt')\n",
    "\n",
    "\tdftest = pd.read_table(test_file, header = None, delim_whitespace=True, names = col_list)\n",
    "\t\n",
    "\t# train_file = os.path.normpath(cwd + '/train/X_train.txt')\n",
    "\t\n",
    "\t# dftrain = pd.read_table(train_file, header = None, delim_whitespace=True, names = col_list)\n",
    "\t\n",
    "\t# # df.append(df2)\n",
    "\t# df = dftest.append(dftrain)\n",
    "\t\n",
    "\t# return(df)\n",
    "\treturn(dftest)\n",
    "\n",
    "\n",
    "def drop_columns(df):\n",
    "\tdrop_list = ['angle','band']\n",
    "\tfor col in df.columns.values:\n",
    "\t    for item in drop_list:\n",
    "\t        test = col.find(item) # returns -1 if item not found\n",
    "\t        #print(\"col is {} and item is {} and test is {}\".format(col,item, test))\n",
    "\t#         print(\"test val = {}\".format(test))\n",
    "\t        if test == -1:\n",
    "\t            pass\n",
    "\t            #print(\"keeping these = find value {} --- finding {} column value {}\".format(test,item, col))\n",
    "\t            \n",
    "\t        else:\n",
    "\t            #print(\"droping these = find value {} --- finding {} column value {}\".format(test,item, col))\n",
    "\t            df.drop(col, axis = 1, inplace = True)\n",
    "\t#             new_cols.remove(col) # useful to keep track of new list of columns in new df - could just use df.column.values though\n",
    "\t            break # if its in the drop list drop and stop looking\n",
    "\treturn(df)\n",
    "\n",
    "\n",
    "def create_labels(df):\n",
    "\t# file_list = ['/test/y_test.txt','/train/y_train.txt']\n",
    "\tfile_list = ['/test/y_test.txt']\n",
    "\tcat_list = []\n",
    "\tact_num = []\n",
    "\tfor file in file_list:\n",
    "\t\tin_file = os.path.normpath(cwd + file)\n",
    "\t\twith open(in_file ,'r+') as cat_file:  \n",
    "\t\t\tfor line in cat_file: # one line is one column\n",
    "\t\t\t\tline = line.strip()\n",
    "\t\t\t\tif '1' in line:\n",
    "\t\t\t\t    activity = 'WALKING'\n",
    "\t\t\t\telif '2' in line:\n",
    "\t\t\t\t    activity  = 'WALKING_UPSTAIRS'\n",
    "\t\t\t\telif '3' in line:\n",
    "\t\t\t\t    activity  = 'WALKING_DOWNSTAIRS'\n",
    "\t\t\t\telif '4' in line:\n",
    "\t\t\t\t    activity  = 'SITTING'\n",
    "\t\t\t\telif '5' in line:\n",
    "\t\t\t\t    activity  = 'STANDING'\n",
    "\t\t\t\telif '6' in line:\n",
    "\t\t\t\t    activity  = 'LAYING' \n",
    "\t\t\t\telse:\n",
    "\t\t\t\t    print(\"error here\")\n",
    "\t\t\t\t    \n",
    "\t\t\t\tcat_list.append(activity)\n",
    "\t\t\t\tact_num.append(line)\n",
    "\t        \n",
    "\t  \n",
    "\t    #print(cat_list)\n",
    "\t# print('Length of cat_list is {}'.format(len(cat_list)))\t\n",
    "\t# print('Shape of df is {}'.format(df.shape))\n",
    "\tdf['activity'] = cat_list # actual activity\n",
    "\tdf['act_num'] = act_num\n",
    "\treturn(df)\n",
    "\n",
    "def get_labels():\n",
    "\tlabel_list = []\n",
    "\t\n",
    "\twith open('new_labels.txt','r+') as new_label_file:\n",
    "\t    \n",
    "\t    for line in new_label_file: # one line is one column\n",
    "\t        line = line.strip()\n",
    "\t        label_list.append(line)\n",
    "\t        #print(cat_list)\n",
    "\t    \n",
    "\t\t# df['label'] = label_list # computed from just the 5 values\n",
    "\t# labels = pd.Series(label_list, index = ['1','2','3','4','5','6']) original modified next line\n",
    "\tlabels = pd.Series(label_list)\n",
    "\t# df1.loc[:,'f'] = p.Series(np.random.randn(sLength), index=df1.index)\n",
    "\t# df.loc[:,'label'] = labels\n",
    "\t\n",
    "\t# df['label']=labels\n",
    "\treturn(labels)\n",
    "\n",
    "def set_actual(df): # ************ why wasn't train in here too?\n",
    "\t# get unique list of activities\n",
    "\tfile = os.path.normpath(cwd + '/test/y_test.txt')\n",
    "\twith open(file ,'r+') as cat_file:\n",
    "\t    num_list = []\n",
    "\t    for line in cat_file: # one line is one column\n",
    "\t        line = line.strip()\n",
    "\t        num_list.append(line)\n",
    "\t        #print(cat_list)\n",
    "\t    \n",
    "\tdf['act_num'] = num_list # numerical representation of activity\n",
    "\treturn(df)\n",
    "\t\n",
    "\n",
    "\n",
    "def make_preds(df, labels):\n",
    "\tdf = df.drop('activity', axis=1) # axis 1 denotes a column not a row\n",
    "\n",
    "\tdf['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "\n",
    "\ttrain, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "# \tprint(test.shape, train.shape)\n",
    "\tfeatures = df.columns[:] # changed from :4 - many features may be a little bit important\n",
    "\t\n",
    "\tclf = RandomForestClassifier(n_jobs=2)\n",
    "\n",
    "\tclf.fit(train[features], train['act_num'])\n",
    "\n",
    "\t# Kyle's code starts here\n",
    "\tpreds = clf.predict(test[features]) #ask kyle about features\n",
    "\t\n",
    "\ts1 = test['act_num']\n",
    "\t# s2 = pd.Series(preds)\n",
    "\n",
    "\t# s1 = pd.Series(test['activity'])\n",
    "\ts2 = pd.Series(preds)\n",
    "\ts2.index = np.arange(len(s2)) # This index needs to be reset\n",
    "\ts1.index = np.arange(len(s1)) # This one doesn't have to be\n",
    "\tresult_df = pd.concat([s1, s2], axis=1)\n",
    "# \tprint(result_df.shape)\n",
    "\tresult_df.columns = ['actual', 'predicted']\n",
    "\tprint(result_df.head())\n",
    "\tcross = pd.crosstab(result_df.actual, result_df.predicted)\n",
    "    \n",
    "\tprint(cross)\n",
    "\treturn(cross)\n",
    "\n",
    "\n",
    "def crosstab():\n",
    "\t\n",
    "\t# get the columns and clean them up\n",
    "\tcol_list = trans_columns()\n",
    "\t\n",
    "\t# concatenate the test and train data sets\n",
    "\tdf = get_data(col_list)\n",
    "\tdf = drop_columns(df)\n",
    "\tdf = create_labels(df)\n",
    "\tlabels = get_labels()\n",
    "\t# df = set_actual(df) # consolidated into create_labels\n",
    "\t# df = pre_process_labels(df)\n",
    "\tcross = make_preds(df, labels)\n",
    "\t\n",
    "\n",
    "\tprint(cross)\n",
    "\treturn(cross)\n",
    "\n",
    "\n",
    "def main():\n",
    "\tc = crosstab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  actual predicted\n",
      "0      5         5\n",
      "1      5         5\n",
      "2      5         5\n",
      "3      5         5\n",
      "4      5         5\n",
      "predicted    1    2   3    4    5    6\n",
      "actual                                \n",
      "1          122    2   0    0    0    0\n",
      "2            1  111   0    0    0    0\n",
      "3            0    1  98    0    0    0\n",
      "4            0    0   0  124    1    0\n",
      "5            0    0   0    2  125    0\n",
      "6            0    0   0    0    0  125\n",
      "predicted    1    2   3    4    5    6\n",
      "actual                                \n",
      "1          122    2   0    0    0    0\n",
      "2            1  111   0    0    0    0\n",
      "3            0    1  98    0    0    0\n",
      "4            0    0   0  124    1    0\n",
      "5            0    0   0    2  125    0\n",
      "6            0    0   0    0    0  125\n"
     ]
    }
   ],
   "source": [
    "c = crosstab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted    1    2   3    4    5    6\n",
       "actual                                \n",
       "1          122    2   0    0    0    0\n",
       "2            1  111   0    0    0    0\n",
       "3            0    1  98    0    0    0\n",
       "4            0    0   0  124    1    0\n",
       "5            0    0   0    2  125    0\n",
       "6            0    0   0    0    0  125"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# s2 = pd.Series(preds)\n",
    "\n",
    "# s1 = pd.Series(test['activity'])\n",
    "s2 = pd.Series(preds)\n",
    "s2.index = np.arange(len(s2)) # This index needs to be reset\n",
    "s1.index = np.arange(len(s1)) # This one doesn't have to be\n",
    "result_df = pd.concat([s1, s2], axis=1)\n",
    "# \tprint(result_df.shape)\n",
    "result_df.columns = ['actual', 'predicted']\n",
    "print(result_df.head())\n",
    "cross = pd.crosstab(result_df.actual, result_df.predicted)\n",
    "\n",
    "print(cross)\n",
    "return(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_list = trans_columns()\n",
    "df = get_data(col_list)\n",
    "df = drop_columns(df)\n",
    "df = create_labels(df)\n",
    "labels = get_labels()\n",
    "\n",
    "# make_preds(df, labels):\n",
    "df = df.drop('activity', axis=1) # axis 1 denotes a column not a row\n",
    "\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "# \tprint(test.shape, train.shape)\n",
    "features = df.columns[:] # changed from :4\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=2)\n",
    "\n",
    "clf.fit(train[features], train['act_num'])\n",
    "\n",
    "# Kyle's code starts here\n",
    "preds = clf.predict(test[features]) #ask kyle about features\n",
    "\n",
    "s1 = test['act_num']\n",
    "s2 = pd.Series(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      5\n",
       "2      5\n",
       "3      5\n",
       "4      5\n",
       "5      5\n",
       "6      4\n",
       "7      4\n",
       "8      4\n",
       "9      4\n",
       "10     4\n",
       "11     4\n",
       "12     4\n",
       "13     4\n",
       "14     4\n",
       "15     4\n",
       "16     6\n",
       "17     6\n",
       "18     6\n",
       "19     6\n",
       "20     6\n",
       "21     6\n",
       "22     6\n",
       "23     6\n",
       "24     6\n",
       "25     1\n",
       "26     1\n",
       "27     1\n",
       "28     1\n",
       "29     1\n",
       "      ..\n",
       "649    4\n",
       "650    4\n",
       "651    4\n",
       "652    4\n",
       "653    4\n",
       "654    6\n",
       "655    6\n",
       "656    6\n",
       "657    6\n",
       "658    6\n",
       "659    6\n",
       "660    6\n",
       "661    1\n",
       "662    1\n",
       "663    1\n",
       "664    1\n",
       "665    1\n",
       "666    1\n",
       "667    1\n",
       "668    3\n",
       "669    3\n",
       "670    3\n",
       "671    2\n",
       "672    2\n",
       "673    3\n",
       "674    3\n",
       "675    3\n",
       "676    3\n",
       "677    3\n",
       "678    2\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    NaN\n",
       "5    NaN\n",
       "5    NaN\n",
       "5    NaN\n",
       "5    NaN\n",
       "5    NaN\n",
       "5    NaN\n",
       "5    NaN\n",
       "4    NaN\n",
       "4    NaN\n",
       "4    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "    ... \n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "6    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "1    NaN\n",
       "3    NaN\n",
       "3    NaN\n",
       "3    NaN\n",
       "3    NaN\n",
       "3    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "2    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5' '5' '5' '5' '5' '5' '5' '5' '4' '4' '4' '6' '6' '6' '6' '6' '6' '6'\n",
      " '6' '6' '6' '6' '1' '1' '1' '1' '1' '1' '1' '1' '3' '3' '3' '3' '2' '2'\n",
      " '2' '2' '2' '5' '5' '5' '5' '5' '5' '4' '4' '4' '4' '4' '4' '6' '6' '6'\n",
      " '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1' '1' '1' '1' '3' '3' '3'\n",
      " '3' '2' '2' '2' '2' '2' '2' '5' '4' '5' '5' '5' '4' '4' '6' '6' '6' '6'\n",
      " '6' '6' '1' '1' '1' '1' '1' '1' '1' '1' '3' '3' '3' '3' '3' '3' '3' '3'\n",
      " '3' '3' '2' '2' '2' '2' '2' '2' '3' '2' '5' '5' '5' '5' '5' '4' '4' '4'\n",
      " '4' '4' '4' '4' '4' '4' '6' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1'\n",
      " '1' '1' '3' '3' '3' '3' '2' '2' '2' '2' '2' '2' '5' '5' '5' '5' '5' '5'\n",
      " '5' '5' '4' '4' '4' '4' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1'\n",
      " '3' '3' '3' '2' '2' '2' '2' '5' '5' '5' '5' '5' '5' '4' '4' '5' '4' '4'\n",
      " '4' '6' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '3' '3' '3' '2'\n",
      " '2' '2' '3' '3' '3' '5' '5' '5' '5' '4' '6' '6' '6' '6' '6' '6' '6' '6'\n",
      " '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1' '1' '1' '1' '3' '3' '3' '3'\n",
      " '3' '2' '2' '2' '2' '2' '2' '2' '2' '2' '5' '5' '5' '5' '4' '4' '4' '4'\n",
      " '4' '4' '4' '4' '4' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '3' '3' '3' '3' '3' '3' '3' '2' '2' '5' '5' '5' '5' '5' '5'\n",
      " '5' '4' '4' '4' '4' '6' '6' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1'\n",
      " '1' '1' '3' '3' '3' '3' '3' '2' '2' '2' '2' '2' '5' '5' '5' '5' '5' '5'\n",
      " '5' '5' '5' '4' '4' '4' '4' '4' '4' '6' '6' '6' '6' '6' '6' '6' '1' '1'\n",
      " '1' '1' '1' '1' '1' '3' '3' '3' '3' '3' '3' '2' '2' '2' '2' '2' '2' '2'\n",
      " '5' '5' '4' '4' '4' '4' '4' '5' '5' '4' '4' '6' '6' '6' '6' '6' '6' '1'\n",
      " '1' '1' '1' '1' '1' '3' '1' '3' '3' '3' '3' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '2' '2' '2' '5' '5' '5' '5' '5' '5' '5' '5' '4' '4' '4' '4' '4' '6'\n",
      " '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '3' '3' '2' '2' '2' '2' '2' '2'\n",
      " '5' '5' '5' '5' '4' '5' '5' '5' '5' '5' '4' '4' '4' '4' '4' '4' '4' '4'\n",
      " '4' '4' '4' '6' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1' '3'\n",
      " '2' '2' '3' '3' '3' '2' '2' '2' '2' '2' '3' '3' '2' '2' '5' '5' '5' '5'\n",
      " '5' '5' '5' '5' '5' '5' '4' '4' '4' '4' '4' '4' '4' '4' '6' '6' '6' '6'\n",
      " '6' '6' '6' '1' '1' '1' '1' '3' '2' '3' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '3' '3' '3' '3' '5' '5' '5' '5' '5' '5' '5' '5' '5' '4' '4' '4' '4' '4'\n",
      " '4' '4' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1'\n",
      " '1' '3' '3' '3' '3' '3' '3' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '5'\n",
      " '5' '5' '5' '5' '5' '5' '5' '5' '5' '4' '4' '4' '4' '6' '6' '6' '6' '6'\n",
      " '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1' '1' '1' '3' '3' '3'\n",
      " '3' '2' '2' '2' '2' '5' '5' '5' '5' '5' '5' '5' '5' '5' '4' '4' '4' '4'\n",
      " '4' '4' '6' '6' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '3' '3' '3' '3' '3' '3' '3' '3' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
      " '2' '5' '5' '5' '5' '5' '5' '5' '5' '4' '4' '4' '4' '4' '4' '4' '4' '6'\n",
      " '6' '6' '6' '6' '6' '6' '6' '6' '6' '1' '1' '1' '1' '1' '1' '1' '3' '3'\n",
      " '3' '3' '3' '2' '2' '2' '2' '2' '2' '2' '2' '3' '2' '2' '2' '2']\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test[features]) #ask kyle about features\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
